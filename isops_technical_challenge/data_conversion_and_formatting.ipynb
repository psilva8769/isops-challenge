{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fec210-7240-4c3d-a2fe-af2b604228b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library and declare the path to the Dados_Candidatos file to start the ETL process.\n",
    "import pandas as pd\n",
    "\n",
    "# Insert the path to the Dados_Candidatos.xlsx file. (Ex: D:\\Desafio_ISOps\\Dados_Candidatos.xlsx)\n",
    "PATH_TO_DADOS_CANDIDATOS_FILE = ''\n",
    "\n",
    "# 1. Reading and setting some parameters to avoid false positives when transforming data.\n",
    "\n",
    "DATA = pd.read_excel(PATH_TO_DADOS_CANDIDATOS_FILE)\n",
    "DATA.is_copy = False\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e5dc9-ceec-469d-bfa1-147128b70625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transposing rows of 'Etapa' into distinct columns.\n",
    "\n",
    "transposed_data = DATA.fillna(value=0).pivot_table(index=['ID_Candidato', 'Nome_Candidato', 'ID_Vaga', 'Nome_Vaga', \n",
    "                                                          'Data_Candidatura', 'Status', 'Motivo_Reprovação'],\n",
    "                                                    columns='Etapa',\n",
    "                                                    values='Data_Movimentacao',\n",
    "                                                    aggfunc='last').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17012ab9-c7f1-4812-ae89-c5a70b062922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter out duplicate dates for a potential merge.\n",
    "\n",
    "'''\n",
    "    Create a separate column with the registration date to select the last value and apply a merge on the main table.\n",
    "'''\n",
    "\n",
    "registration_data = DATA[DATA['Etapa'] == 'Cadastro'][['ID_Candidato', 'Data_Movimentacao']].rename(columns={'Data_Movimentacao': 'Cadastro'})\n",
    "transposed_data = pd.merge(transposed_data, registration_data, on='ID_Candidato', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd091e-74cd-421e-a948-07d7841d6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Aggregate all values from the created column to the main column.\n",
    "\n",
    "transposed_data.loc[~transposed_data['Cadastro_x'].isin(transposed_data['Cadastro_y']), 'Cadastro_x'] = transposed_data['Cadastro_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937317c0-7f9e-4a78-a8bd-d4d00e6bdff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Removal of duplicate values -> Renaming the Cadastro_x column back to its original name (Cadastro) -> Removing unnecessary extra indices.\n",
    "\n",
    "transposed_data = transposed_data.drop_duplicates(subset=['ID_Candidato'], keep='last'\n",
    "                                                  ).rename(columns={'Cadastro_x':'Cadastro'}\n",
    "                                                          ).drop(columns=['Cadastro_y']\n",
    "                                                                ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f4ff2-fdee-476b-8a70-8ca3256e4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Remapping of columns (supposed chronological order).\n",
    "\n",
    "ordered_columns = ['ID_Candidato', 'Nome_Candidato', 'ID_Vaga', 'Nome_Vaga', 'Data_Candidatura', \n",
    "                   'Status', 'Cadastro', 'Triagem', 'Entrevista TA', 'Teste Técnico', \n",
    "                   'Entrevista RH', 'Entrevista Final', 'Oferta', 'Contratação', 'Motivo_Reprovação']\n",
    "\n",
    "ordered_data = transposed_data[ordered_columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9e2d3-f70e-4b1f-9b48-74ecfd3e8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "7. Replacement of the 0s assigned in step 2 with null values and \n",
    "formatting of the date columns to meet the established criterion: ISO8601 formatting\n",
    "'''\n",
    "\n",
    "'''\n",
    "The check_cell_data_type function is used to verify if the data type of a given cell in a specific column\n",
    "is in the datetime64[ns] format (the standard Excel format for Date type cells).\n",
    "\n",
    "Possible outcomes:\n",
    "True: The correct value to meet the ISO8601 formatting criterion is assigned to the cell.\n",
    "False: A null value (NA) is assigned to the cell.\n",
    "'''\n",
    "\n",
    "def check_cell_data_type(cell_value):\n",
    "    if pd.api.types.is_datetime64_any_dtype(cell_value):\n",
    "        return pd.NA if pd.isna(cell_value) else cell_value.date()\n",
    "    else:\n",
    "        return cell_value\n",
    "\n",
    "for column in ordered_data.columns[0:]:\n",
    "    ordered_data[column] = ordered_data[column].replace(0, pd.NA).apply(check_cell_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88205bc4-e526-4430-a8ee-79c41649363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Export the final dataframe to a CSV file.\n",
    "\n",
    "ordered_data.to_csv('Clean and Structured Data.csv', index=False, encoding='utf-8-sig', date_format=\"%Y-%m-%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
